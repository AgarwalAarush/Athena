//
//  WakeWordTranscriptionManager.swift
//  Athena
//
//  Manages wake word detection and automatic transcription with VAD
//

import Foundation
import Speech
import AVFoundation
import Combine

/// State machine for wake word + transcription workflow
enum WakeWordState {
    case idle
    case listeningForWakeWord
    case transcribing
    case cooldown
}

/// Manages the complete wake word â†’ transcribe â†’ VAD â†’ repeat cycle
@MainActor
class WakeWordTranscriptionManager: ObservableObject {

    // MARK: - Published Properties

    @Published private(set) var state: WakeWordState = .idle
    @Published private(set) var partialTranscript: String = ""
    @Published private(set) var finalTranscript: String?

    // MARK: - Private Properties

    private var wakeWordDetector: WakeWordDetector?
    private var vadTranscriber: SimplifiedVADTranscriber?

    private var audioEngine: AVAudioEngine?
    private var audioInput: AVAudioInputNode?

    private var detectorTask: Task<Void, Never>?
    private var transcriberTask: Task<Void, Never>?
    
    private let _amplitudeMonitor = AudioAmplitudeMonitor()
    
    /// Public read-only access to amplitude monitor for UI visualization
    var amplitudeMonitor: AudioAmplitudeMonitor {
        _amplitudeMonitor
    }

    // Current transcript from the speech recognizer
    private var lastSessionTranscript: String = ""

    // Ring buffer for audio handoff (captures last ~1 second of audio)
    private var audioRingBuffer: [AVAudioPCMBuffer] = []
    private let maxRingBufferDuration: TimeInterval = 1.0 // 1 second of audio
    private var currentRingBufferDuration: TimeInterval = 0.0

    // Callback invoked when wake word is detected (e.g., to show hidden window)
    var onWakeWordDetectedCallback: (() -> Void)?

    // MARK: - Initialization

    init() {
        print("[WakeWordTranscriptionManager] Initializing with simplified VAD")
    }

    deinit {
        detectorTask?.cancel()
        transcriberTask?.cancel()
        Task { @MainActor in
            self.stopAudioEngine()
        }
    }

    // MARK: - Public Methods

    func start() async throws {
        print("[WakeWordTranscriptionManager] ğŸ¬ start() called - current state: \(state)")

        guard state == .idle else {
            print("[WakeWordTranscriptionManager] âš ï¸ Cannot start - already running (state: \(state))")
            print("[WakeWordTranscriptionManager] ğŸ’¡ This usually means stop() wasn't called properly before starting again")
            return
        }

        print("[WakeWordTranscriptionManager] âœ… State is idle, proceeding with start")

        // Check authorizations
        try await checkAuthorizations()

        // Start audio engine
        try startAudioEngine()

        // Start amplitude monitor
        print("[WakeWordTranscriptionManager] âš¡ Starting amplitude monitor")
        _amplitudeMonitor.start()

        // Start listening for wake word
        try await startWakeWordDetection()

        print("[WakeWordTranscriptionManager] ğŸ‰ Wake word mode fully started and listening")
    }

    func stop() {
        print("[WakeWordTranscriptionManager] ğŸ›‘ Stopping wake word mode (current state: \(state))")
        
        // CRITICAL: Set to idle FIRST to prevent start() from being blocked
        state = .idle
        print("[WakeWordTranscriptionManager] âš™ï¸ State immediately set to .idle")
        
        // Now do synchronous cleanup in proper order
        detectorTask?.cancel()
        transcriberTask?.cancel()
        
        wakeWordDetector?.stop()
        wakeWordDetector = nil  // Fully release
        
        vadTranscriber?.stop()
        vadTranscriber = nil  // Fully release
        
        // Stop amplitude monitor
        _amplitudeMonitor.stop()
        
        // Stop audio engine LAST (after all consumers are stopped)
        stopAudioEngine()
        
        // Clear all state
        partialTranscript = ""
        finalTranscript = nil
        lastSessionTranscript = ""
        clearRingBuffer()
        
        print("[WakeWordTranscriptionManager] âœ… Wake word mode stopped - fully cleaned up and ready for restart")
    }

    // MARK: - Private Methods - Authorization

    private func checkAuthorizations() async throws {
        // Check speech recognition authorization
        let speechStatus = SFSpeechRecognizer.authorizationStatus()
        if speechStatus != .authorized {
            throw WakeWordError.notAuthorized
        }

        // Check microphone authorization
        let micStatus = AVCaptureDevice.authorizationStatus(for: .audio)
        if micStatus != .authorized {
            throw WakeWordError.notAuthorized
        }
    }

    // MARK: - Private Methods - Audio Engine

    private func startAudioEngine() throws {
        stopAudioEngine()

        let audioEngine = AVAudioEngine()
        let inputNode = audioEngine.inputNode
        let bus = 0

        let format = inputNode.inputFormat(forBus: bus)

        // Install tap to process audio
        inputNode.installTap(onBus: bus, bufferSize: 1024, format: format) { [weak self] buffer, _ in
            Task { @MainActor [weak self] in
                await self?.processAudioBuffer(buffer)
            }
        }

        // Start engine
        try audioEngine.start()

        self.audioEngine = audioEngine
        self.audioInput = inputNode

        print("[WakeWordTranscriptionManager] Audio engine started")
    }

    private func stopAudioEngine() {
        if let inputNode = audioInput {
            inputNode.removeTap(onBus: 0)
        }

        audioEngine?.stop()
        audioEngine = nil
        audioInput = nil

        print("[WakeWordTranscriptionManager] Audio engine stopped")
    }

    private var bufferCount = 0

    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) async {
        // Process amplitude for waveform visualization (in all active states)
        // CRITICAL: Use fire-and-forget Task to prevent blocking audio thread
        if state == .listeningForWakeWord || state == .transcribing {
            if let channelData = buffer.floatChannelData {
                let frameCount = Int(buffer.frameLength)
                let samples = Array(UnsafeBufferPointer(start: channelData[0], count: frameCount))

                let audioFrame = AudioFrame(
                    samples: samples,
                    sampleRate: buffer.format.sampleRate,
                    timestamp: AVAudioTime(hostTime: mach_absolute_time())
                )

                bufferCount += 1
                // Fire-and-forget: Don't await to prevent audio thread blocking
                Task { @MainActor in
                    if bufferCount % 50 == 0 {
                        print("[WakeWordTranscriptionManager] ğŸµ Processing audio buffer #\(bufferCount) for amplitude monitor (samples: \(samples.count))")
                    }
                    await _amplitudeMonitor.process(audioFrame)
                }
            }
        }
        
        switch state {
        case .listeningForWakeWord:
            // Add to ring buffer for smooth handoff
            addToRingBuffer(buffer)
            
            // Send audio to wake word detector
            wakeWordDetector?.processAudioBuffer(buffer)

        case .transcribing:
            // Send audio to VAD transcriber
            vadTranscriber?.appendAudioBuffer(buffer)

        case .idle:
            // No processing during idle
            break

        case .cooldown:
            // No processing during cooldown
            break
        }
    }

    // MARK: - Ring Buffer Management
    
    private func addToRingBuffer(_ buffer: AVAudioPCMBuffer) {
        // Calculate duration of this buffer
        let bufferDuration = Double(buffer.frameLength) / buffer.format.sampleRate
        
        // Add new buffer
        audioRingBuffer.append(buffer)
        currentRingBufferDuration += bufferDuration
        
        // Remove old buffers to maintain ~1 second window
        while currentRingBufferDuration > maxRingBufferDuration && !audioRingBuffer.isEmpty {
            let oldBuffer = audioRingBuffer.removeFirst()
            let oldDuration = Double(oldBuffer.frameLength) / oldBuffer.format.sampleRate
            currentRingBufferDuration -= oldDuration
        }
    }
    
    private func clearRingBuffer() {
        audioRingBuffer.removeAll()
        currentRingBufferDuration = 0.0
    }
    
    private func feedRingBufferToTranscriber() {
        guard let transcriber = vadTranscriber else { return }
        
        let bufferCount = audioRingBuffer.count
        print("[WakeWordTranscriptionManager] ğŸ”„ Feeding \(bufferCount) buffered audio frames (~\(String(format: "%.2f", currentRingBufferDuration))s) to transcriber")
        
        for buffer in audioRingBuffer {
            transcriber.appendAudioBuffer(buffer)
        }
        
        // Clear the ring buffer after feeding to transcriber
        clearRingBuffer()
    }

    // MARK: - Private Methods - Wake Word Detection

    private func startWakeWordDetection() async throws {
        print("[WakeWordTranscriptionManager] Starting wake word detection")

        let detector = try WakeWordDetector()
        self.wakeWordDetector = detector

        try detector.start()

        state = .listeningForWakeWord

        // Listen for wake word events
        detectorTask = Task { [weak self] in
            guard let self = self else { return }

            for await _ in detector.events {
                await self.onWakeWordDetected()
            }
        }
    }

    private func onWakeWordDetected() async {
        print("[WakeWordTranscriptionManager] ğŸ¤ Wake word detected! Transitioning to transcription mode...")
        print("[WakeWordTranscriptionManager] ğŸ“Š Current state: \(state)")

        // Notify external listeners (e.g., to show hidden window)
        onWakeWordDetectedCallback?()

        // Stop wake word detection and clear its buffer
        print("[WakeWordTranscriptionManager] ğŸ›‘ Stopping wake word detector and clearing buffer")
        wakeWordDetector?.stop()
        detectorTask?.cancel()
        wakeWordDetector = nil // Fully release to clear buffer

        // Start full transcription with VAD
        do {
            print("[WakeWordTranscriptionManager] ğŸ¬ Starting VAD transcription")
            try await startTranscription()
        } catch {
            print("[WakeWordTranscriptionManager] âŒ Error starting transcription: \(error)")
            // Clear ring buffer on error
            clearRingBuffer()
            // Fall back to wake word detection
            print("[WakeWordTranscriptionManager] ğŸ”„ Falling back to wake word detection")
            try? await startWakeWordDetection()
        }
    }

    // MARK: - Private Methods - Transcription

    private func startTranscription() async throws {
        print("[WakeWordTranscriptionManager] ğŸ“ Starting transcription with VAD")

        print("[WakeWordTranscriptionManager] ğŸ”„ State transition: \(state) â†’ .transcribing")
        state = .transcribing
        partialTranscript = ""
        finalTranscript = nil

        // Reset transcript for this new transcription session
        lastSessionTranscript = ""
        print("[WakeWordTranscriptionManager] ğŸ”„ Reset transcript - starting fresh transcription session")

        print("[WakeWordTranscriptionManager] ğŸ—ï¸ Creating SimplifiedVADTranscriber with 1s silence timeout")
        let transcriber = try SimplifiedVADTranscriber(silenceTimeout: 1)
        self.vadTranscriber = transcriber

        print("[WakeWordTranscriptionManager] â–¶ï¸ Starting VAD transcriber")
        try transcriber.start()

        // Clear the ring buffer to avoid transcribing the wake word
        print("[WakeWordTranscriptionManager] ğŸ§¹ Clearing ring buffer to avoid transcribing wake word")
        clearRingBuffer()

        print("[WakeWordTranscriptionManager] ğŸ§ Starting event listener for transcription")
        // Listen for transcription events
        transcriberTask = Task { [weak self] in
            guard let self = self else { return }

            for await event in transcriber.events {
                await self.handleTranscriptEvent(event)
            }
        }

        print("[WakeWordTranscriptionManager] âœ… Transcription started - audio will now route to VAD")
    }

    private func handleTranscriptEvent(_ event: TranscriptEvent) async {
        switch event {
        case .partial(let text):
            // Speech recognizer internally accumulates, so just use the latest transcript
            print("[WakeWordTranscriptionManager] ğŸ“ Partial: '\(text)'")
            lastSessionTranscript = text
            partialTranscript = text

        case .final(let text, let confidence):
            let confidenceStr = confidence.map { String(format: "%.2f", $0) } ?? "N/A"
            print("[WakeWordTranscriptionManager] âœ… Final transcript: '\(text)' (confidence: \(confidenceStr))")
            
            lastSessionTranscript = text
            partialTranscript = text

            // Note: Don't end transcription on final - wait for VAD silence detection

        case .silenceDetected:
            print("[WakeWordTranscriptionManager] ğŸ”‡ Silence detected - ending transcription session")
            print("[WakeWordTranscriptionManager] ğŸ“Š Full transcript: '\(lastSessionTranscript)'")

            finalTranscript = lastSessionTranscript.isEmpty ? nil : lastSessionTranscript
            await onSilenceDetected()

        case .error(let error):
            print("[WakeWordTranscriptionManager] âŒ Transcription error: \(error)")
            print("[WakeWordTranscriptionManager] ğŸ“Š State at error: \(state), lastSession: '\(lastSessionTranscript)'")
            await onTranscriptionEnded()

        case .ended:
            print("[WakeWordTranscriptionManager] ğŸ Transcription ended normally")
            print("[WakeWordTranscriptionManager] ğŸ“Š LastSession: '\(lastSessionTranscript)'")
            await onTranscriptionEnded()
        }
    }

    private func onSilenceDetected() async {
        print("[WakeWordTranscriptionManager] ğŸ”„ Transcription complete, returning to wake word detection")

        // Stop transcription
        print("[WakeWordTranscriptionManager] ğŸ›‘ Stopping transcription")
        stopTranscription()

        // Clear transcript for next session
        print("[WakeWordTranscriptionManager] ğŸ§¹ Clearing transcript for next wake word session")
        lastSessionTranscript = ""

        // Small cooldown before restarting wake word detection
        print("[WakeWordTranscriptionManager] â¸ï¸ Entering cooldown period (0.5s)")
        state = .cooldown
        try? await Task.sleep(nanoseconds: 500_000_000) // 0.5 seconds

        // Return to wake word detection
        do {
            print("[WakeWordTranscriptionManager] ğŸ”„ Restarting wake word detection after cooldown")
            try await startWakeWordDetection()
        } catch {
            print("[WakeWordTranscriptionManager] âŒ Error restarting wake word detection: \(error)")
            state = .idle
        }
    }

    private func onTranscriptionEnded() async {
        print("[WakeWordTranscriptionManager] ğŸ”š Transcription ended (error or completion), returning to wake word detection")

        print("[WakeWordTranscriptionManager] ğŸ›‘ Stopping transcription")
        stopTranscription()

        // Clear transcript for next session
        print("[WakeWordTranscriptionManager] ğŸ§¹ Clearing transcript for next wake word session")
        lastSessionTranscript = ""

        // Return to wake word detection immediately (no cooldown on error)
        do {
            print("[WakeWordTranscriptionManager] ğŸ”„ Restarting wake word detection")
            try await startWakeWordDetection()
        } catch {
            print("[WakeWordTranscriptionManager] âŒ Error restarting wake word detection: \(error)")
            state = .idle
        }
    }

    private func stopTranscription() {
        print("[WakeWordTranscriptionManager] ğŸ§¹ Cleaning up transcription resources")
        transcriberTask?.cancel()
        vadTranscriber?.stop()
        vadTranscriber = nil
    }

    // MARK: - Public Configuration

    /// Update the VAD silence timeout (in seconds)
    /// - Parameter timeout: Silence duration in seconds before ending transcription (e.g., 2.0 for 2 seconds)
    func setSilenceTimeout(_ timeout: TimeInterval) {
        print("[WakeWordTranscriptionManager] ğŸ›ï¸ Updating VAD silence timeout to \(timeout)s")
        vadTranscriber?.setSilenceTimeout(timeout)
    }
}
